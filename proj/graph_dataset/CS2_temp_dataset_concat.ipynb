{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awpy import Demo\n",
    "\n",
    "import torch\n",
    "from torch_geometric_temporal.signal import DynamicHeteroGraphTemporalSignal\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from termcolor import colored\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "pl.Config.set_tbl_rows(10)\n",
    "\n",
    "sys.path.append(os.path.abspath('../../package'))\n",
    "\n",
    "from CS2.graph import TabularGraphSnapshot, HeteroGraphSnapshot, TemporalHeteroGraphSnapshot\n",
    "from CS2.token import Tokenizer\n",
    "from CS2.preprocess import Dictionary, NormalizePosition, NormalizeTabularGraphSnapshot, ImputeTabularGraphSnapshot\n",
    "from CS2.visualize import HeteroGraphVisualizer\n",
    "\n",
    "DATA_PATH = '../../data/matches-processed/cs2/temporal-hetero-graph/'\n",
    "DATA_SAVE_PATH = '../../data/matches-processed/cs2/temporal-hetero-graph/concat/'\n",
    "PROCESS_SAVE_PATH = './parses/temp-hetero-parse-2024.10.13/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat single matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8266\n",
      "8266\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '100070.pt',\n",
    "    '100071.pt',\n",
    "    '100072.pt',\n",
    "    '100073.pt',\n",
    "    '100074.pt',\n",
    "    '100075.pt',\n",
    "    '100076.pt',\n",
    "    '100077.pt',\n",
    "    '100078.pt',\n",
    "    '100079.pt',\n",
    "]\n",
    "\n",
    "lens = 0\n",
    "concat_list = []\n",
    "\n",
    "for match in files:\n",
    "    match = torch.load(os.path.join(DATA_PATH, match), weights_only=False)\n",
    "    lens += len(match)\n",
    "    concat_list.extend(match)\n",
    "\n",
    "print(lens)\n",
    "print(len(concat_list))\n",
    "\n",
    "torch.save(concat_list, DATA_SAVE_PATH + '100070-100079.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8956\n",
      "8956\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '100080.pt',\n",
    "    '100081.pt',\n",
    "    '100082.pt',\n",
    "    '100083.pt',\n",
    "    '100084.pt',\n",
    "    '100085.pt',\n",
    "    '100086.pt',\n",
    "    '100087.pt',\n",
    "    '100088.pt',\n",
    "    '100089.pt',\n",
    "]\n",
    "\n",
    "lens = 0\n",
    "concat_list = []\n",
    "\n",
    "for match in files:\n",
    "    match = torch.load(os.path.join(DATA_PATH, match), weights_only=False)\n",
    "    lens += len(match)\n",
    "    concat_list.extend(match)\n",
    "\n",
    "print(lens)\n",
    "print(len(concat_list))\n",
    "\n",
    "torch.save(concat_list, DATA_SAVE_PATH + '100080-100089.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9468\n",
      "9468\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '100090.pt',\n",
    "    '100091.pt',\n",
    "    '100092.pt',\n",
    "    '100093.pt',\n",
    "    '100094.pt',\n",
    "    '100095.pt',\n",
    "    '100096.pt',\n",
    "    '100097.pt',\n",
    "    '100098.pt',\n",
    "    '100099.pt',\n",
    "]\n",
    "\n",
    "lens = 0\n",
    "concat_list = []\n",
    "\n",
    "for match in files:\n",
    "    match = torch.load(os.path.join(DATA_PATH, match), weights_only=False)\n",
    "    lens += len(match)\n",
    "    concat_list.extend(match)\n",
    "\n",
    "print(lens)\n",
    "print(len(concat_list))\n",
    "\n",
    "torch.save(concat_list, DATA_SAVE_PATH + '100090-100099.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9395\n",
      "9395\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '100100.pt',\n",
    "    '100101.pt',\n",
    "    '100102.pt',\n",
    "    '100103.pt',\n",
    "    '100104.pt',\n",
    "    '100105.pt',\n",
    "    '100106.pt',\n",
    "    '100107.pt',\n",
    "    '100108.pt',\n",
    "    '100109.pt',\n",
    "]\n",
    "\n",
    "lens = 0\n",
    "concat_list = []\n",
    "\n",
    "for match in files:\n",
    "    match = torch.load(os.path.join(DATA_PATH, match), weights_only=False)\n",
    "    lens += len(match)\n",
    "    concat_list.extend(match)\n",
    "\n",
    "print(lens)\n",
    "print(len(concat_list))\n",
    "\n",
    "torch.save(concat_list, DATA_SAVE_PATH + '100100-100109.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3010\n",
      "3010\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    '100110.pt',\n",
    "    '100111.pt',\n",
    "    '100112.pt',\n",
    "    '100113.pt',\n",
    "]\n",
    "\n",
    "lens = 0\n",
    "concat_list = []\n",
    "\n",
    "for match in files:\n",
    "    match = torch.load(os.path.join(DATA_PATH, match), weights_only=False)\n",
    "    lens += len(match)\n",
    "    concat_list.extend(match)\n",
    "\n",
    "print(lens)\n",
    "print(len(concat_list))\n",
    "\n",
    "torch.save(concat_list, DATA_SAVE_PATH + '100110-100113.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000-100009.pt\n",
      "Loaded 100010-100019.pt\n",
      "Loaded 100020-100029.pt\n",
      "Loaded 100030-100039.pt\n",
      "Loaded 100040-100049.pt\n",
      "Loaded 100050-100059.pt\n",
      "Loaded 100060-100069.pt\n",
      "Loaded 100070-100079.pt\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    '100000-100009.pt',\n",
    "    '100010-100019.pt',\n",
    "    '100020-100029.pt',\n",
    "    '100030-100039.pt',\n",
    "    '100040-100049.pt',\n",
    "    '100050-100059.pt',\n",
    "    '100060-100069.pt',\n",
    "    '100070-100079.pt',\n",
    "]\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for file in file_names:\n",
    "\n",
    "    match_graphs = torch.load(DATA_SAVE_PATH + file, weights_only=False)\n",
    "    train_data.extend(match_graphs)\n",
    "    print(f'Loaded {file}')\n",
    "\n",
    "torch.save(train_data, DATA_PATH + '/train.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100080-100089.pt\n",
      "Loaded 100090-100099.pt\n",
      "Loaded 100110-100113.pt\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    '100080-100089.pt',\n",
    "    '100090-100099.pt',\n",
    "    '100110-100113.pt',\n",
    "]\n",
    "\n",
    "val_data = []\n",
    "\n",
    "for file in file_names:\n",
    "\n",
    "    match_graphs = torch.load(DATA_SAVE_PATH + file, weights_only=False)\n",
    "    val_data.extend(match_graphs)\n",
    "    print(f'Loaded {file}')\n",
    "\n",
    "torch.save(val_data, DATA_PATH + '/val.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67269"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torch.load(DATA_PATH + '100000.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thgs = TemporalHeteroGraphSnapshot()\n",
    "dyn_graphs = thgs.process_match(test_data, interval=20, shifted_intervals=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
