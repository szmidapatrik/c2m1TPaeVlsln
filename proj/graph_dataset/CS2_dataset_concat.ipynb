{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "DATA_PATH = '../../data/matches-processed/cs2/hetero-graph/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat single matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    '100110.pt',\n",
    "    '100111.pt',\n",
    "    '100112.pt',\n",
    "    '100113.pt'\n",
    "]\n",
    "\n",
    "lens = 0\n",
    "concat_list = []\n",
    "\n",
    "for file in file_names:\n",
    "    data = torch.load(DATA_PATH + file, weights_only=False)\n",
    "    lens += len(data)\n",
    "    concat_list.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32364\n",
      "32364\n"
     ]
    }
   ],
   "source": [
    "print(lens)\n",
    "print(len(concat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(concat_list, DATA_PATH + '/concat/100110-100113.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bomb planted datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100000-100009.pt\n",
      "Saved 100010-100019.pt\n",
      "Saved 100020-100029.pt\n",
      "Saved 100030-100039.pt\n",
      "Saved 100040-100049.pt\n",
      "Saved 100050-100059.pt\n",
      "Saved 100060-100069.pt\n",
      "Saved 100070-100079.pt\n",
      "Saved 100080-100089.pt\n",
      "Saved 100090-100099.pt\n",
      "Saved 100100-100109.pt\n",
      "Saved 100110-100113.pt\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    '100000-100009.pt',\n",
    "    '100010-100019.pt',\n",
    "    '100020-100029.pt',\n",
    "    '100030-100039.pt',\n",
    "    '100040-100049.pt',\n",
    "    '100050-100059.pt',\n",
    "    '100060-100069.pt',\n",
    "    '100070-100079.pt',\n",
    "    '100080-100089.pt',\n",
    "    '100090-100099.pt',\n",
    "    '100100-100109.pt',\n",
    "    '100110-100113.pt'\n",
    "]\n",
    "\n",
    "for file_name in file_names:\n",
    "\n",
    "    match_graphs = torch.load(DATA_PATH + '/concat/' + file_name, weights_only=False)\n",
    "    bomb_planted = []\n",
    "\n",
    "    for graph in match_graphs:\n",
    "        if graph.y['is_bomb_planted_at_A_site'] == np.float16(1) or graph.y['is_bomb_planted_at_B_site'] == np.float16(1):\n",
    "            bomb_planted.append(graph)\n",
    "\n",
    "    torch.save(bomb_planted, DATA_PATH + '/bomb_planted/' + file_name)\n",
    "    print(f'Saved {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs in 100000-100009.pt: 18199\n",
      "Graphs in 100010-100019.pt: 14658\n",
      "Graphs in 100020-100029.pt: 17705\n",
      "Graphs in 100030-100039.pt: 17674\n",
      "Graphs in 100040-100049.pt: 19612\n",
      "Graphs in 100050-100059.pt: 15886\n",
      "Graphs in 100060-100069.pt: 16954\n",
      "Graphs in 100070-100079.pt: 19228\n",
      "Graphs in 100080-100089.pt: 19015\n",
      "Graphs in 100090-100099.pt: 17290\n",
      "Graphs in 100100-100109.pt: 15621\n"
     ]
    }
   ],
   "source": [
    "bomb_file_names = [\n",
    "    '100000-100009.pt',\n",
    "    '100010-100019.pt',\n",
    "    '100020-100029.pt',\n",
    "    '100030-100039.pt',\n",
    "    '100040-100049.pt',\n",
    "    '100050-100059.pt',\n",
    "    '100060-100069.pt',\n",
    "    '100070-100079.pt',\n",
    "    '100080-100089.pt',\n",
    "    '100090-100099.pt',\n",
    "    '100100-100109.pt',\n",
    "]\n",
    "\n",
    "for file_name in bomb_file_names:\n",
    "\n",
    "    match_graphs = torch.load(DATA_PATH + '/bomb_planted/' + file_name, weights_only=False)\n",
    "    print(f'Graphs in {file_name}: {len(match_graphs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000-100009.pt\n",
      "Loaded 100010-100019.pt\n",
      "Loaded 100020-100029.pt\n",
      "Loaded 100030-100039.pt\n",
      "Loaded 100040-100049.pt\n",
      "Loaded 100050-100059.pt\n",
      "Loaded 100060-100069.pt\n",
      "Loaded 100070-100079.pt\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    '100000-100009.pt',\n",
    "    '100010-100019.pt',\n",
    "    '100020-100029.pt',\n",
    "    '100030-100039.pt',\n",
    "    '100040-100049.pt',\n",
    "    '100050-100059.pt',\n",
    "    '100060-100069.pt',\n",
    "    '100070-100079.pt',\n",
    "]\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for file in file_names:\n",
    "\n",
    "    match_graphs = torch.load(DATA_PATH + '/concat/' + file, weights_only=False)\n",
    "    train_data.extend(match_graphs)\n",
    "    print(f'Loaded {file}')\n",
    "\n",
    "torch.save(train_data, DATA_PATH + '/train.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.460989681602123\n"
     ]
    }
   ],
   "source": [
    "ct_wins = 0\n",
    "for grapf in train_data:\n",
    "    if grapf.y['CT_wins'] == np.float16(1):\n",
    "        ct_wins += 1\n",
    "\n",
    "print(ct_wins / len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1904578614098638\n"
     ]
    }
   ],
   "source": [
    "planted = 0\n",
    "for grapf in train_data:\n",
    "    if grapf.y['is_bomb_planted_at_A_site'] == np.float16(1) or grapf.y['is_bomb_planted_at_B_site'] == np.float16(1):\n",
    "        planted += 1\n",
    "\n",
    "print(planted / len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100080-100089.pt\n",
      "Loaded 100090-100099.pt\n",
      "Loaded 100110-100113.pt\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    '100080-100089.pt',\n",
    "    '100090-100099.pt',\n",
    "    '100110-100113.pt',\n",
    "]\n",
    "\n",
    "val_data = []\n",
    "\n",
    "for file in file_names:\n",
    "\n",
    "    match_graphs = torch.load(DATA_PATH + '/concat/' + file, weights_only=False)\n",
    "    val_data.extend(match_graphs)\n",
    "    print(f'Loaded {file}')\n",
    "\n",
    "torch.save(val_data, DATA_PATH + '/val.pt')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4753377821166045\n"
     ]
    }
   ],
   "source": [
    "ct_wins = 0\n",
    "for graph in val_data:\n",
    "    if graph.y['CT_wins'] == np.float16(1):\n",
    "        ct_wins += 1\n",
    "\n",
    "print(ct_wins / len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output variable validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000-100009.pt: 0.1513700155936734\n",
      "100010-100019.pt: 0.13963410224889725\n",
      "100020-100029.pt: 0.14991181657848324\n",
      "100030-100039.pt: 0.15914067585962005\n",
      "100040-100049.pt: 0.17005404135338345\n",
      "100050-100059.pt: 0.20787236520321417\n",
      "100060-100069.pt: 0.12294350842418236\n",
      "100070-100079.pt: 0.12441417234268574\n",
      "100080-100089.pt: 0.1735626928791862\n",
      "100090-100099.pt: 0.18470373270686505\n",
      "100100-100109.pt: 0.1546796560465232\n",
      "100110-100113.pt: 0.20327820869310698\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(DATA_PATH + '/bomb_planted/'):\n",
    "\n",
    "    train_data = torch.load(DATA_PATH + f'/bomb_planted/{file}', weights_only=False)\n",
    "\n",
    "    ct_wins = 0\n",
    "    for graph in train_data:\n",
    "        if graph.y['CT_wins'] == np.float16(1):\n",
    "            ct_wins += 1\n",
    "\n",
    "    print(file + ': ' + str(ct_wins / len(train_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
