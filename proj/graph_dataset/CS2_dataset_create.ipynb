{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awpy import Demo\n",
    "\n",
    "import torch\n",
    "from torch_geometric_temporal.signal import DynamicHeteroGraphTemporalSignal\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "pl.Config.set_tbl_rows(10)\n",
    "\n",
    "sys.path.append(os.path.abspath('../../package'))\n",
    "\n",
    "from CS2.graph import TabularGraphSnapshot, HeteroGraphSnapshot, TemporalHeteroGraphSnapshot\n",
    "from CS2.token import Tokenizer\n",
    "from CS2.preprocess import Dictionary, NormalizePosition, NormalizeTabularGraphSnapshot, ImputeTabularGraphSnapshot\n",
    "from CS2.visualize import HeteroGraphVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tabular Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2024 Matches\n",
    "\n",
    "Parse date: 2024. 09. 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _iem-dallas-2024-virtuspro-vs-big-bo3-iNJygOnxyHMLcZ0aB_CRymvirtus-pro-vs-big-m1-inferno.dem\n",
      "Parse completed. Duration: 95.31853127479553 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _iem-katowice-2024-eternal-fire-vs-faze-bo3-NSvOwra3ZJLAlQou2jhAKveternal-fire-vs-faze-m1-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 199.3240532875061 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _iem-katowice-2024-faze-vs-g2-bo3-lDSpEKhlCSD-s8pPYcVur4faze-vs-g2-m1-inferno.dem\n",
      "Parse completed. Duration: 146.53006839752197 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-cloud9-vs-vitality-bo3-RvWbJFcoqQS_A5b3fq8wkNcloud9-vs-vitality-m1-inferno.dem\n",
      "Parse completed. Duration: 170.02403354644775 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-complexity-vs-vitality-bo3-sY4ulkzdMckO1RJnk-7NRfcomplexity-vs-vitality-m1-inferno.dem\n",
      "Parse completed. Duration: 246.5257167816162 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-ecstatic-vs-furia-bo3-jK3FVXUKON0PJXIYi9-tsDecstatic-vs-furia-m2-inferno.dem\n",
      "Parse completed. Duration: 210.49236226081848 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-ecstatic-vs-g2-bo3-T_ST9R3kdudNZcw587UGLuecstatic-vs-g2-m1-inferno.dem\n",
      "Parse completed. Duration: 127.57550239562988 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-eternal-fire-vs-natus-vincere-bo3-9-IU6vp4Wb-l2e_bLhJGeveternal-fire-vs-natus-vincere-m2-inferno.dem\n",
      "Parse completed. Duration: 154.8290023803711 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-eternal-fire-vs-virtuspro-bo3--WE3FAQTdtn9TPHht4Fs3geternal-fire-vs-virtus-pro-m3-inferno.dem\n",
      "Parse completed. Duration: 183.16489624977112 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-faze-vs-natus-vincere-bo3-QEOvW4A6iftqXM-MiRXq-9faze-vs-natus-vincere-m3-inferno.dem\n",
      "Parse completed. Duration: 100.35375881195068 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-g2-vs-furia-inferno-aEobAWRtETpILX6JssSwLJg2-vs-furia-inferno.dem\n",
      "Parse completed. Duration: 108.8416063785553 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-mouz-vs-g2-bo3-k_35u4wuU34XSYjyDaZHTnmouz-vs-g2-m1-inferno.dem\n",
      "Parse completed. Duration: 141.55666184425354 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-pain-vs-themongolz-bo3-jpqXxmTQx0XX8DCgl82DgYpain-vs-themongolz-m3-inferno.dem\n",
      "Parse completed. Duration: 303.8512783050537 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-virtuspro-vs-g2-bo3-_HljkSgUssxnv7gY6zueWRvirtus-pro-vs-g2-m2-inferno.dem\n",
      "Parse completed. Duration: 172.18947672843933 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-virtuspro-vs-imperial-inferno-khjhOWhI70GAS-g9WWfGzcvirtus-pro-vs-imperial-inferno.dem\n",
      "Parse completed. Duration: 140.26580476760864 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-virtuspro-vs-pain-inferno-y7t-XNpP0lvaarNCS0wDsrvirtuspro-vs-pain-inferno.dem\n",
      "Parse completed. Duration: 155.8233585357666 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-vitality-vs-eternal-fire-inferno-QBb8rgnBMHzXVHQ7TZ2P3cvitality-vs-eternal-fire-inferno.dem\n",
      "Parse completed. Duration: 160.40541458129883 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _pgl-cs2-major-copenhagen-2024-vitality-vs-faze-bo3-jlkLGLV1kDcMWp0cgIFaOAvitality-vs-faze-m3-inferno.dem\n",
      "Parse completed. Duration: 130.37977409362793 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-astralis-vs-the-mongolz-inferno-earakkDVhibcVDxYwAPYuRastralis-vs-the-mongolz-inferno.dem\n",
      "Parse completed. Duration: 144.4377248287201 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-complexity-vs-big-inferno-0NOZtg3Sw8z-wQPgDTN6_8complexity-vs-big-inferno.dem\n",
      "Parse completed. Duration: 174.03921389579773 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-complexity-vs-furia-inferno-nNF-QzYEPXKM32ZGDbj_Xqcomplexity-vs-furia-inferno.dem\n",
      "Parse completed. Duration: 163.6999752521515 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-fnatic-vs-big-inferno-PGmium5sp075-0ESvPfepPfnatic-vs-big-inferno.dem\n",
      "Parse completed. Duration: 166.66892409324646 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-fnatic-vs-complexity-inferno-RPqFbgQPKY_Eg7wLUNnFlDfnatic-vs-complexity-inferno.dem\n",
      "Parse completed. Duration: 146.0157973766327 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-fnatic-vs-eternal-fire-inferno-GSUcS96CMxUgd1WzqGOGdPfnatic-vs-eternal-fire-inferno.dem\n",
      "Parse completed. Duration: 141.7229197025299 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _yalla-compass-2024-furia-vs-eternal-fire-inferno-SSZyDA3jM4nvvNf1UckE2Gfuria-vs-eternal-fire-inferno.dem\n",
      "Parse completed. Duration: 149.89701223373413 seconds.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# PREPARATION\n",
    "# --------------------------------------------------\n",
    "\n",
    "MATCH_FOLDER_PATH = '../../data/matches-raw/cs2/2024/'\n",
    "SAVE_PATH = '../../data/matches-processed/cs2/tabular/2024/'\n",
    "\n",
    "# Get inferno matches\n",
    "match_list = os.listdir(MATCH_FOLDER_PATH)\n",
    "inferno_match_list = [file for file in match_list if 'inferno' in file and \n",
    "    '-p1' not in file and \n",
    "    '-p2' not in file and \n",
    "    '-p3' not in file and \n",
    "    '-p4' not in file and \n",
    "    '-p5' not in file\n",
    "]\n",
    "\n",
    "# Save complete match list and process time\n",
    "parsed_matches_list = []\n",
    "error_matches_list = []\n",
    "process_time_list = []\n",
    "\n",
    "# Match index\n",
    "match_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# Read the files if they exist\n",
    "if os.path.exists('completed_matches.txt'):\n",
    "    with open('completed_matches.txt', 'r') as file:\n",
    "        parsed_matches_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('error_matches.txt'):\n",
    "    with open('error_matches.txt', 'r') as file:\n",
    "        error_matches_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('process_times.txt'):\n",
    "    with open('process_times.txt', 'r') as file:\n",
    "        process_time_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('match_index.txt'):\n",
    "    with open('match_index.txt', 'r') as file:\n",
    "        match_index = int(file.read())\n",
    "\n",
    "\n",
    "# Map nodes dataset\n",
    "nodes = pd.read_csv('../../data/map_graph_model/de_inferno/nodes.csv')\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PARSE MATCHES\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Parse Inferno matches\n",
    "for match in inferno_match_list:\n",
    "\n",
    "    # If the match has already been parsed or is corrupted, skip it\n",
    "    if match in parsed_matches_list or match in error_matches_list:\n",
    "        continue\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Match path\n",
    "    match_path = MATCH_FOLDER_PATH + match\n",
    "\n",
    "    # Create tabular snapshot object\n",
    "    tg = TabularGraphSnapshot()\n",
    "\n",
    "    print('-----------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('                                                        PARSING MATCH                                                        \\n')\n",
    "    print('Match: ' + match)\n",
    "\n",
    "    try:\n",
    "        # Create tabular snapshot database\n",
    "        df, df_dict, active_infernos, active_smokes, active_he_smokes = tg.process_match(\n",
    "            match_path=match_path,\n",
    "            player_stats_data_path='../../data/player-stats/scraped-in-2024/2023/norm_player_stats_2023.csv',\n",
    "            missing_player_stats_data_path='../../data/player-stats/missing_players_df_2023.csv',\n",
    "            weapon_data_path='../../data/weapon_info/ammo_info.csv',\n",
    "\n",
    "            ticks_per_second=4,\n",
    "            numerical_match_id=100000 + match_index,\n",
    "            num_permutations_per_round=1,\n",
    "            build_dictionary=True,\n",
    "\n",
    "            package='pandas'\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print info and save error matches\n",
    "        print('Error occured while parsing the match. Skipping match.')\n",
    "\n",
    "        error_matches_list.append(match)\n",
    "        with open('error_matches.txt', 'w') as file:\n",
    "            for item in error_matches_list:\n",
    "                file.write(f\"{item}\\n\")\n",
    "                \n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    # Impute missing values\n",
    "    its = ImputeTabularGraphSnapshot()\n",
    "    df = its.impute(df)\n",
    "\n",
    "    # Tokenize match\n",
    "    tokenizer = Tokenizer()\n",
    "    df = tokenizer.tokenize_match(df, 'de_inferno', nodes)\n",
    "\n",
    "    # Save dataframes\n",
    "    df.to_csv(SAVE_PATH + match + '_df.csv', index=False)\n",
    "    df_dict.to_csv(SAVE_PATH + match + '_df_dict.csv', index=False)\n",
    "    active_infernos.to_csv(SAVE_PATH + match + '_active_infernos.csv', index=False)\n",
    "    active_smokes.to_csv(SAVE_PATH + match + '_active_smokes.csv', index=False)\n",
    "    active_he_smokes.to_csv(SAVE_PATH + match + '_active_he_smokes.csv', index=False)\n",
    "\n",
    "    # Post-process\n",
    "    match_index += 1\n",
    "    parsed_matches_list.append(match)\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # LOG AND SAVE TIME\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "    # Time\n",
    "    end_time = time.time()\n",
    "    process_time = end_time - start_time\n",
    "    process_time_list.append(process_time)\n",
    "\n",
    "    # Write results to file\n",
    "    with open('completed_matches.txt', 'w') as file:\n",
    "        for item in parsed_matches_list:\n",
    "            file.write(f\"{item}\\n\")\n",
    "    \n",
    "    with open('process_times.txt', 'w') as file:\n",
    "        for item in process_time_list:\n",
    "            file.write(f\"{item}\\n\")\n",
    "    \n",
    "    with open('match_index.txt', 'w') as file:\n",
    "        file.write(str(match_index))\n",
    "\n",
    "    print('Parse completed. Duration: ' + str(process_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2023 Matches\n",
    "\n",
    "Parse date: 2024. 09. 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _iem-sydney-2023-mouz-vs-vertex-inferno-wyV4hHh3mDqNZhY8zBC_ttmouz-vs-vertex-inferno.dem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-17 20:54:00.247\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mawpy.parsers.events\u001b[0m:\u001b[36mparse_bomb\u001b[0m:\u001b[36m279\u001b[0m - \u001b[33m\u001b[1mbomb_defused not found in events.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Error occured while parsing the match. Skipping match.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _iem-sydney-2023-natus-vincere-vs-mouz-bo3-kmz24m_e2rc4e07yRHJsFcnatus-vincere-vs-mouz-m2-inferno.dem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-17 20:55:20.532\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mawpy.parsers.events\u001b[0m:\u001b[36mparse_bomb\u001b[0m:\u001b[36m309\u001b[0m - \u001b[33m\u001b[1mbomb_exploded not found in events.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Error occured while parsing the match. Skipping match.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _iem-sydney-2023-vitality-vs-faze-bo3-KYy8n7ELEDs3OUXK1CHiYpvitality-vs-faze-m2-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Error occured while parsing the match. Skipping match.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _roobet-cup-2023-fnatic-vs-ninjas-in-pyjamas-bo3-vvaeYNK3nyhj-S-LM5M0XFfnatic-vs-ninjas-in-pyjamas-m1-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 136.1281979084015 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _roobet-cup-2023-movistar-riders-vs-9z-bo3-BJXqYVFljEe0r6OFEd3Q3fmovistar-riders-vs-9z-m3-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 122.54090237617493 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _roobet-cup-2023-og-vs-fnatic-bo3-dOx3-3kXMqUOqAbeTpUgeTog-vs-fnatic-m3-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 122.54380464553833 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _thunderpick-world-championship-2023-cloud9-vs-fnatic-bo3-PrE8KE3k48_amsejzYryEicloud9-vs-fnatic-m3-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 137.216317653656 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _thunderpick-world-championship-2023-complexity-vs-mouz-bo3-uBfFO_IJlkwKFOq4f4uOyccomplexity-vs-mouz-m3-inferno.dem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-17 21:07:33.113\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mawpy.parsers.events\u001b[0m:\u001b[36mparse_bomb\u001b[0m:\u001b[36m279\u001b[0m - \u001b[33m\u001b[1mbomb_defused not found in events.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 81.6461410522461 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _thunderpick-world-championship-2023-fnatic-vs-ninjas-in-pyjamas-bo3-6iVaParaf7r9nrM0X_nIUKfnatic-vs-ninjas-in-pyjamas-m2-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 195.55537915229797 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _thunderpick-world-championship-2023-fnatic-vs-virtuspro-bo3-TIXlP91jgLe7XdTNek2melfnatic-vs-virtus-pro-m2-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Parse completed. Duration: 288.2054376602173 seconds.\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "                                                        PARSING MATCH                                                        \n",
      "\n",
      "Match: _thunderpick-world-championship-2023-ninjas-in-pyjamas-vs-virtuspro-bo3-hZMHo4HYjYRM_rTdbZFf07ninjas-in-pyjamas-vs-virtus-pro-m3-inferno.dem\n",
      "\u001b[1m\u001b[33mWarning:\u001b[0m ['in_crouch', 'ducking', 'in_duck_jump'] columns were missing during the parse. Added the missing columns with values 0.\n",
      "Error occured while parsing the match. Skipping match.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------\n",
    "# PREPARATION\n",
    "# --------------------------------------------------\n",
    "\n",
    "MATCH_FOLDER_PATH = '../../data/matches-raw/cs2/2023/'\n",
    "SAVE_PATH = '../../data/matches-processed/cs2/tabular/2023/'\n",
    "\n",
    "# Get inferno matches\n",
    "match_list = os.listdir(MATCH_FOLDER_PATH)\n",
    "inferno_match_list = [file for file in match_list if 'inferno' in file and \n",
    "    '-p1' not in file and \n",
    "    '-p2' not in file and \n",
    "    '-p3' not in file and \n",
    "    '-p4' not in file and \n",
    "    '-p5' not in file\n",
    "]\n",
    "\n",
    "# Save complete match list and process time\n",
    "parsed_matches_list = []\n",
    "error_matches_list = []\n",
    "process_time_list = []\n",
    "\n",
    "# Match index\n",
    "match_index = 0\n",
    "\n",
    "\n",
    "\n",
    "# Read the files if they exist\n",
    "if os.path.exists('completed_matches.txt'):\n",
    "    with open('completed_matches.txt', 'r') as file:\n",
    "        parsed_matches_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('error_matches.txt'):\n",
    "    with open('error_matches.txt', 'r') as file:\n",
    "        error_matches_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('process_times.txt'):\n",
    "    with open('process_times.txt', 'r') as file:\n",
    "        process_time_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('match_index.txt'):\n",
    "    with open('match_index.txt', 'r') as file:\n",
    "        match_index = int(file.read())\n",
    "\n",
    "\n",
    "# Map nodes dataset\n",
    "nodes = pd.read_csv('../../data/map_graph_model/de_inferno/nodes.csv')\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PARSE MATCHES\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Parse Inferno matches\n",
    "for match in inferno_match_list:\n",
    "\n",
    "    # If the match has already been parsed or is corrupted, skip it\n",
    "    if match in parsed_matches_list or match in error_matches_list:\n",
    "        continue\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Match path\n",
    "    match_path = MATCH_FOLDER_PATH + match\n",
    "\n",
    "    # Create tabular snapshot object\n",
    "    tg = TabularGraphSnapshot()\n",
    "\n",
    "    print('-----------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('                                                        PARSING MATCH                                                        \\n')\n",
    "    print('Match: ' + match)\n",
    "\n",
    "    try:\n",
    "        # Create tabular snapshot database\n",
    "        df, df_dict, active_infernos, active_smokes, active_he_smokes = tg.process_match(\n",
    "            match_path=match_path,\n",
    "            player_stats_data_path='../../data/player-stats/scraped-in-2024/2022/norm_player_stats_2022.csv',\n",
    "            missing_player_stats_data_path='../../data/player-stats/missing_players_df_2022.csv',\n",
    "            weapon_data_path='../../data/weapon_info/ammo_info.csv',\n",
    "\n",
    "            ticks_per_second=4,\n",
    "            numerical_match_id=100000 + match_index,\n",
    "            num_permutations_per_round=1,\n",
    "            build_dictionary=True,\n",
    "\n",
    "            package='pandas'\n",
    "        )\n",
    "\n",
    "        # Impute missing values\n",
    "        its = ImputeTabularGraphSnapshot()\n",
    "        df = its.impute(df)\n",
    "\n",
    "        # Tokenize match\n",
    "        tokenizer = Tokenizer()\n",
    "        df = tokenizer.tokenize_match(df, 'de_inferno', nodes)\n",
    "\n",
    "        # Save dataframes\n",
    "        df.to_csv(SAVE_PATH + match + '_df.csv', index=False)\n",
    "        df_dict.to_csv(SAVE_PATH + match + '_df_dict.csv', index=False)\n",
    "        active_infernos.to_csv(SAVE_PATH + match + '_active_infernos.csv', index=False)\n",
    "        active_smokes.to_csv(SAVE_PATH + match + '_active_smokes.csv', index=False)\n",
    "        active_he_smokes.to_csv(SAVE_PATH + match + '_active_he_smokes.csv', index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print info and save error matches\n",
    "        print('Error occured while parsing the match. Skipping match.')\n",
    "\n",
    "        error_matches_list.append(match)\n",
    "        with open('error_matches.txt', 'w') as file:\n",
    "            for item in error_matches_list:\n",
    "                file.write(f\"{item}\\n\")\n",
    "                \n",
    "        continue\n",
    "\n",
    "\n",
    "    # Post-process\n",
    "    match_index += 1\n",
    "    parsed_matches_list.append(match)\n",
    "\n",
    "\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # LOG AND SAVE TIME\n",
    "    # --------------------------------------------------\n",
    "    \n",
    "    # Time\n",
    "    end_time = time.time()\n",
    "    process_time = end_time - start_time\n",
    "    process_time_list.append(process_time)\n",
    "\n",
    "    # Write results to file\n",
    "    with open('completed_matches.txt', 'w') as file:\n",
    "        for item in parsed_matches_list:\n",
    "            file.write(f\"{item}\\n\")\n",
    "    \n",
    "    with open('process_times.txt', 'w') as file:\n",
    "        for item in process_time_list:\n",
    "            file.write(f\"{item}\\n\")\n",
    "    \n",
    "    with open('match_index.txt', 'w') as file:\n",
    "        file.write(str(match_index))\n",
    "\n",
    "    print('Parse completed. Duration: ' + str(process_time) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Heterogeneous Graph Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "MATCH_FOLDER_PATH_2023 = '../../data/matches-processed/cs2/tabular/2023/'\n",
    "MATCH_FOLDER_PATH_2024 = '../../data/matches-processed/cs2/tabular/2024/'\n",
    "\n",
    "# Get files in the folders\n",
    "file_list_2023 = os.listdir(MATCH_FOLDER_PATH_2023)\n",
    "file_list_2024 = os.listdir(MATCH_FOLDER_PATH_2024)\n",
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Build Dictionary\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Get dictionary files\n",
    "df_dict_list_2023 = [file for file in file_list_2023 if file.endswith('_df_dict.csv')]\n",
    "df_dict_list_2024 = [file for file in file_list_2024 if file.endswith('_df_dict.csv')]\n",
    "\n",
    "# Build dictionaries\n",
    "dict_2023 = Dictionary().build_dictionary(MATCH_FOLDER_PATH_2023, df_dict_list_2023)\n",
    "dict_2024 = Dictionary().build_dictionary(MATCH_FOLDER_PATH_2024, df_dict_list_2024)\n",
    "\n",
    "# Merge dictionaries\n",
    "dictionary = Dictionary().merge_dictionaries([dict_2023, dict_2024])\n",
    "\n",
    "# Save dictionary\n",
    "dictionary.to_csv('dictionary_2023-2024.09.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Create Heterogeneous Graph Snahpots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph save path\n",
    "GRAPH_SAVE_PATH = '../../data/matches-processed/cs2/hetero-graph/'\n",
    "\n",
    "# Get match list\n",
    "df_match_list_2023 = [file for file in file_list_2023 if file.endswith('_df.csv')]\n",
    "\n",
    "# Get CONFIG parameters\n",
    "inferno_pos_norm_config = '../../config/map_normalization/inferno.json'\n",
    "molotov_radius_config = '../../config/nade_radius/molotov_norm.json'\n",
    "smoke_radius_config = '../../config/nade_radius/smoke_norm.json'\n",
    "\n",
    "with open(inferno_pos_norm_config, 'r') as f:\n",
    "    CONFIG_INF_POS_NORM = json.load(f)\n",
    "with open(molotov_radius_config, 'r') as f:\n",
    "    CONFIG_MOLOTOV_RADIUS = json.load(f)\n",
    "with open(smoke_radius_config, 'r') as f:\n",
    "    CONFIG_SMOKE_RADIUS = json.load(f)\n",
    "\n",
    "# Nodes and edges dataframes\n",
    "nodes_to_use = pd.read_csv('../../data/map_graph_model/de_inferno/nodes_norm.csv')\n",
    "edges = pd.read_csv('../../data/map_graph_model/de_inferno/edges.csv')\n",
    "\n",
    "# Save complete match list and process time\n",
    "parsed_matches_list = []\n",
    "error_matches_list = []\n",
    "process_time_list = []\n",
    "\n",
    "# Read the files if they exist\n",
    "if os.path.exists('completed_matches.txt'):\n",
    "    with open('completed_matches.txt', 'r') as file:\n",
    "        parsed_matches_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('error_matches.txt'):\n",
    "    with open('error_matches.txt', 'r') as file:\n",
    "        error_matches_list = [line.strip() for line in file]\n",
    "\n",
    "if os.path.exists('process_times.txt'):\n",
    "    with open('process_times.txt', 'r') as file:\n",
    "        process_time_list = [line.strip() for line in file]\n",
    "\n",
    "\n",
    "# Iterate over the matches\n",
    "for match in df_match_list_2023:\n",
    "\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('-----------------------------------------------------------------------------------------------------------------------------')\n",
    "    print('                                                        PARSING MATCH                                                        \\n')\n",
    "    print('Match: ' + match)\n",
    "\n",
    "    try:\n",
    "        # Read dataframes\n",
    "        df = pd.read_csv(MATCH_FOLDER_PATH_2023 + match)\n",
    "        active_infernos = pd.read_csv(MATCH_FOLDER_PATH_2023 + match.replace('_df.csv', '_active_infernos.csv'))\n",
    "        active_smokes = pd.read_csv(MATCH_FOLDER_PATH_2023 + match.replace('_df.csv', '_active_smokes.csv'))\n",
    "        try:\n",
    "            active_he_smokes = pd.read_csv(MATCH_FOLDER_PATH_2023 + match.replace('_df.csv', '_active_he_smokes.csv'))\n",
    "        except:\n",
    "            active_he_smokes = pd.DataFrame(columns=['tick', 'round', 'X', 'Y', 'Z'])\n",
    "            print('No HE thrown into smokes in the match. Creating empty dataframe.')\n",
    "\n",
    "        # Normalize active nade dataframes\n",
    "        np = NormalizePosition()\n",
    "        active_infernos = np.normalize(active_infernos, CONFIG_INF_POS_NORM)\n",
    "        active_smokes = np.normalize(active_smokes, CONFIG_INF_POS_NORM)\n",
    "        active_he_smokes = np.normalize(active_he_smokes, CONFIG_INF_POS_NORM)\n",
    "\n",
    "        # Normalize tabular snapshot\n",
    "        nts = NormalizeTabularGraphSnapshot()\n",
    "        df = nts.noramlize(df, dictionary, CONFIG_INF_POS_NORM)\n",
    "\n",
    "        # Graph snapshots\n",
    "        hg = HeteroGraphSnapshot()\n",
    "        graphs = hg.process_snapshots(df, nodes_to_use, edges, active_infernos, active_smokes, active_he_smokes, CONFIG_MOLOTOV_RADIUS, CONFIG_SMOKE_RADIUS)\n",
    "\n",
    "        # Save graph snapshots\n",
    "        torch.save(graphs, GRAPH_SAVE_PATH + df['NUMERICAL_MATCH_ID'].iloc[0] + '.pt')\n",
    "\n",
    "        # Save post-processed match\n",
    "        parsed_matches_list.append(match)\n",
    "    \n",
    "        # Time\n",
    "        end_time = time.time()\n",
    "        process_time = end_time - start_time\n",
    "        process_time_list.append(process_time)\n",
    "\n",
    "        # Write results to file\n",
    "        with open('completed_matches.txt', 'w') as file:\n",
    "            for item in parsed_matches_list:\n",
    "                file.write(f\"{item}\\n\")\n",
    "        \n",
    "        with open('process_times.txt', 'w') as file:\n",
    "            for item in process_time_list:\n",
    "                file.write(f\"{item}\\n\")\n",
    "\n",
    "        print('Parse completed. Duration: ' + str(process_time) + ' seconds.')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print info and save error matches\n",
    "        print('Error occured while parsing the match. Skipping match.')\n",
    "\n",
    "        error_matches_list.append(match)\n",
    "        with open('error_matches.txt', 'w') as file:\n",
    "            for item in error_matches_list:\n",
    "                file.write(f\"{item}\\n\")\n",
    "                \n",
    "        continue\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
