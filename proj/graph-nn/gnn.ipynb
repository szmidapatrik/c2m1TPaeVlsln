{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heterogeneous GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData, DataLoader, Dataset\n",
    "from torch_geometric.nn import RGCNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, to_hetero, GCNConv\n",
    "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, GraphConv, Linear\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import trim_to_layer\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class InfernoDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        super(InfernoDataset, self).__init__()\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64686"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw = torch.load('data/inferno_graph_dataset.pt')\n",
    "dataset_raw.len()\n",
    "\n",
    "# dataset2 = torch.load('data/inferno_graph_dataset_2.pt')\n",
    "# dataset2.len()\n",
    "\n",
    "# dataset = torch.load('data/inferno_graph_dataset_3.pt')\n",
    "# dataset.len()\n",
    "\n",
    "# Lengths of the datasets\n",
    "# 64686+165182+61479"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  y={\n",
       "    roundNum=1.0,\n",
       "    sec=0.0,\n",
       "    team1AliveNum=5.0,\n",
       "    team2AliveNum=5.0,\n",
       "    CTwinsRound=1\n",
       "  },\n",
       "  \u001b[1mplayer\u001b[0m={ x=[10, 44] },\n",
       "  \u001b[1mmap\u001b[0m={ x=[181, 3] },\n",
       "  \u001b[1m(map, connected_to, map)\u001b[0m={ edge_index=[2, 204] },\n",
       "  \u001b[1m(player, closest_to, map)\u001b[0m={ edge_index=[2, 10] }\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "  for data in dataset:\n",
    "    data['player'].x = data['player'].x[:,:-42]\n",
    "    data['player'].x = F.normalize(data['player'].x, p=2, dim=0)\n",
    "    data['map'].x = F.normalize(data['map'].x, p=2, dim=0)\n",
    "    if data['player'].x.shape == torch.Size([10,43]):\n",
    "      data['player'].x = torch.cat((data['player'].x[:, : -3], torch.zeros((10,1)), data['player'].x[:, -3:]), dim=1)\n",
    "  return dataset\n",
    "\n",
    "dataset = format_dataset(dataset_raw)\n",
    "\n",
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    34022\n",
       "0    30664\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for data in dataset:\n",
    "    y.append(data.y['CTwinsRound'].item())\n",
    "pd.DataFrame(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeterogeneousGNN(\n",
      "  (convs): ModuleList(\n",
      "    (0-3): 4 x HeteroConv(num_relations=2)\n",
      "  )\n",
      "  (lin1): Linear(-1, 256, bias=True)\n",
      "  (lin2): Linear(256, 128, bias=True)\n",
      "  (lin3): Linear(128, 32, bias=True)\n",
      "  (lin4): Linear(32, 1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szmid\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch_geometric\\nn\\conv\\hetero_conv.py:62: UserWarning: There exist node types ({'player'}) whose representations do not get updated during message passing as they do not occur as destination type in any edge type. This may lead to unexpected behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class HeterogeneousGNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_channels, num_layers, edge_types):\n",
    "        super().__init__()\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layernum in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                    edge_type: SAGEConv((-1, -1), hidden_channels)\n",
    "                    for edge_type in edge_types\n",
    "                }, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "        self.lin1 = Linear(-1, 256)\n",
    "        self.lin2 = Linear(256, 128)\n",
    "        self.lin3 = Linear(128, 32)\n",
    "        self.lin4 = Linear(32, 1)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            temp = conv(x_dict, edge_index_dict)\n",
    "            x_dict['map'] = temp['map']\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "            \n",
    "        x = torch.cat([torch.flatten(x_dict['player']), torch.flatten(x_dict['map'])])\n",
    "        x = self.lin1(x).relu()\n",
    "        #print(torch.sum(torch.isnan(x)))\n",
    "        x = self.lin2(x).relu()\n",
    "        x = self.lin3(x).relu()\n",
    "        x = self.lin4(x).sigmoid()\n",
    "        return x\n",
    "\n",
    "model = HeterogeneousGNN(hidden_channels=20, num_layers=4, edge_types=data.edge_types)\n",
    "print(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6016], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset[:64], batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset[64:128], batch_size=1, shuffle=True)\n",
    "data = dataset[0].to('cuda')\n",
    "\n",
    "model = HeterogeneousGNN(hidden_channels=20, num_layers=10, edge_types=data.edge_types).to('cuda')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.1)\n",
    "loss_function = torch.nn.BCELoss()\n",
    "\n",
    "with torch.no_grad():  # Initialize lazy modules.\n",
    "     out = model(data.x_dict, data.edge_index_dict)\n",
    "     print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data.to('cuda')\n",
    "        out = model(data.x_dict, data.edge_index_dict).to(torch.float32)  # Perform a single forward pass.\n",
    "        target = data.y['CTwinsRound'].to(torch.float32)\n",
    "        loss = loss_function(out, target)  # Compute the loss.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        \n",
    "\n",
    "def test(loader):\n",
    "     model.eval()\n",
    "\n",
    "     correct = 0\n",
    "     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "         out = model(data.x, data.edge_index, data.batch)  \n",
    "         pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "         correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "     return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "def validate(val_loader):\n",
    "    model.eval()  # Átkapcsoljuk a modellt értékelési üzemmódba.\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:  # Iterálunk a validációs adatokon.\n",
    "            data.to('cuda')\n",
    "            out = model(data.x_dict, data.edge_index_dict).to(torch.float32)\n",
    "            target = data.y['CTwinsRound'].to(torch.float32)\n",
    "            loss = loss_function(out, target)\n",
    "            total_loss += loss.item()\n",
    "            total_samples += len(target)\n",
    "\n",
    "            # Ellenőrizzük a helyes előrejelzéseket (például egy bináris probléma esetében).\n",
    "            predictions = (out > 0.5).float()\n",
    "            correct_predictions += (predictions == target).sum().item()\n",
    "\n",
    "    # Kiszámítjuk az átlagos veszteséget és a pontosságot.\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return avg_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to('cpu')\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  2 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  3 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  4 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  5 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  6 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  7 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  8 : (avg_loss, accuracy)  (0.0, 1.0)\n",
      "Epoch  9 : (avg_loss, accuracy)  (0.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train()\n",
    "    train_acc = validate(val_loader)\n",
    "    print('Epoch ', epoch, ': (avg_loss, accuracy) ', train_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
