model: HeterogeneousGNN(
  (convs): ModuleList(
    (0-1): 2 x HeteroConv(num_relations=3)
    (2): HeteroConv(num_relations=1)
  )
  (linear): Linear(1123, 16, bias=True)
  (dense): Sequential(
    (0): Linear(in_features=16, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=8, out_features=4, bias=True)
    (4): LeakyReLU(negative_slope=0.01)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4, out_features=1, bias=True)
  )
)
dense_layers: [{'dropout': 0, 'num_of_layers': 1, 'neuron_num': 8, 'input_neuron_num': 16, 'activation_function': LeakyReLU(negative_slope=0.01)}, {'dropout': 0.5}, {'dropout': 0, 'num_of_layers': 1, 'neuron_num': 4, 'input_neuron_num': 8, 'activation_function': LeakyReLU(negative_slope=0.01)}, {'dropout': 0.5}, {'dropout': 0, 'num_of_layers': 1, 'neuron_num': 1, 'input_neuron_num': 4, 'activation_function': None}]
player_dims: [10, 3]
map_dims: [15, 5, 3]
player_attention_heads: None
map_attention_heads: None
trainable_params: 28015
optimizer: AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.002
    maximize: False
    weight_decay: 0.25
)
loss_function: BCEWithLogitsLoss()
batch_size: 500
